dt$Margin = min(dt$minmargperc,dt$maxmargperc)
dt$Margin = pmin(dt$minmargperc,dt$maxmargperc)
mintable = aggregate(Margin~RAIL+Measurement+Note, dt, min)
write.csv(mintable,file="C:/Users/damoore/Documents/2014 Projects/Testing/Vregs/EV4B-M/by Jacob/margins.csv")
write.csv(mintable,file="C:/Users/damoore/Documents/2014 Projects/Testing/Vregs/EV4B-M/by Jacob/margins.csv")
View(mintable)
setkey(mintable,RAIL,Measurement)
write.csv(dt_specs,file="C:/Users/damoore/Documents/2014 Projects/Testing/Vregs/EV4B-M/by Jacob/specs.csv")
dt$MargValue = pmin(dt$MinMargin, dt$MaxMargin)
View(dt)
mintable = aggregate(MargValue~RAIL+Measurement+Note~Min~Typ~Max~Units~TestCase, dt, min)
mintable = aggregate(MargValue~RAIL+Measurement+Note+Min+Typ+Max+Units+TestCase, dt, min)
write.csv(mintable,file="C:/Users/damoore/Documents/2014 Projects/Testing/Vregs/EV4B-M/by Jacob/margins.csv")
mintable = aggregate(MargValue~RAIL+Measurement+Note+Units+TestCase, dt, min)
write.csv(mintable,file="C:/Users/damoore/Documents/2014 Projects/Testing/Vregs/EV4B-M/by Jacob/margins.csv")
stdtable = aggregate(MargValue~RAIL+Measurement+Note+Units+TestCase, dt, std)
?stdev
?sd
stdtable = aggregate(MargValue~RAIL+Measurement+Note+Units+TestCase, dt, sd)
write.csv(stdtable,file="C:/Users/damoore/Documents/2014 Projects/Testing/Vregs/EV4B-M/by Jacob/marginstd.csv")
?aggregate
table = aggregate(cbind(MargValue,Data)~RAIL+Measurement+Note+Units+TestCase, dt, {mean,sd})
table = aggregate(cbind(MargValue,Data)~RAIL+Measurement+Note+Units+TestCase, dt, (mean,sd))
table = aggregate(cbind(MargValue,Data)~RAIL+Measurement+Note+Units+TestCase, dt, mean)
View(table)
write.csv(table,file="C:/Users/damoore/Documents/2014 Projects/Testing/Vregs/EV4B-M/by Jacob/margin2.csv")
?na.action
min(5,7)
min(5,7,NA,na.action=na.omit)
min(5,7,NA,na.action=na.omit
)
min(dt2$Min)
min(dt2$Min, na.action = na.omit)
na.action=na.omit
min(dt2$Min)
dt2$DiffFromMin = dt2$Data[!is.na(dt2$Min)] - dt2$Min[!is.na(dt2$Min)]
dt2$Min[is.na(dt2$min)]
dt2$Min[is.na(dt2$Min)]
dt2$Min[!is.na(dt2$Min)]
dt3 = dt2
dt3$Min[is.na(dt3$Min)] <- 0
View(dt3)
View(dt3)
dt3=dt2
dt3[!is.na(dt3$Min),]
install.packages("RXKCD")
nrows(dt3)
dt3$Data[1]
dt3$Data[100]
for(i in 1:nrow(dt3)) {
if(is.na(dt3$Min[i])) {
dt3$MinMargin[i] = 10000000
} else {
dt3$MinMargin[i] = dt3$Data - dt3$Min
}
if(is.na(dt3$Max[i])) {
dt3$MaxMargin[i] = 10000000
} else {
dt3$MaxMargin[i] = dt3$Max - dt3$Data
}
dt3$Margin[i]=min(dt3$MinMargin[i],dt3$MaxMargin[i])
}
warnings()
for(i in 1:nrow(dt3)) {
if(is.na(dt3$Min[i])) {
dt3$MinMargin[i] = 10000000
} else {
dt3$MinMargin[i] = dt3$Data[i] - dt3$Min[i]
}
if(is.na(dt3$Max[i])) {
dt3$MaxMargin[i] = 10000000
} else {
dt3$MaxMargin[i] = dt3$Max[i] - dt3$Data[i]
}
dt3$Margin[i]=min(dt3$MinMargin[i],dt3$MaxMargin[i])
}
View(dt3)
min(dt3$Margin)
dt3$MinMargin = NULL
dt3$MaxMargin = NULL
View(dt3)
dt3$Margin2 = NULL
dt3$DiffFromMin = NULL
View(dt3)
for(i in 1:nrow(dt3)) {
if(is.na(dt3$Min[i])) {
dt3$MinMargin[i] = 10000000
} else {
dt3$MinMargin[i] = dt3$Data[i] - dt3$Min[i]
}
if(is.na(dt3$Max[i])) {
dt3$MaxMargin[i] = 10000000
} else {
dt3$MaxMargin[i] = dt3$Max[i] - dt3$Data[i]
}
dt3$Margin[i]=min(dt3$MinMargin[i],dt3$MaxMargin[i])
dt3$MarginPerc = min(dt3$MinMargin[i]/dt3$Data[i],dt3$MaxMargin[i]/dt3$Data[i])
}
dt3$MinMargin = NULL
dt3$MaxMargin = NULL
View(dt3)
for(i in 1:nrow(dt3)) {
if(is.na(dt3$Min[i])) {
dt3$MinMargin[i] = 10000000
} else {
dt3$MinMargin[i] = dt3$Data[i] - dt3$Min[i]
}
if(is.na(dt3$Max[i])) {
dt3$MaxMargin[i] = 10000000
} else {
dt3$MaxMargin[i] = dt3$Max[i] - dt3$Data[i]
}
dt3$Margin[i]=min(dt3$MinMargin[i],dt3$MaxMargin[i])
dt3$MarginPerc[i] = min(dt3$MinMargin[i]/dt3$Data[i],dt3$MaxMargin[i]/dt3$Data[i])
}
dt3$MinMargin = NULL
dt3$MaxMargin = NULL
View(dt3)
summary(dt3)
?lapply
table = lapply(dt3,mean,by="RAIL")
table=dt3[,lapply(.SD,mean),by={"RAIL","Measurement"}]
table=dt3[,lapply(.SD,mean),by="RAIL"]
table=dt3[,lapply(mean),by="RAIL"]
table=dt3[,lapply(,mean),by="RAIL"]
table=dt3[,lapply(.SD,mean),by="RAIL"]
dt3.SD
table=dt3[,lapply(dt3,mean),by="RAIL"]
warnings()
table=dt3[,lapply(*,mean),by="RAIL"]
table=dt3[,sapply(*,mean),by="RAIL"]
table=dt3[,lapply(*,mean),by="RAIL"]
write.csv(dt3,file="C:/Users/damoore/Documents/2014 Projects/Testing/Vregs/EV4B-M/by Jacob/margin3.csv")
setwd("C:/Users/damoore/Documents/R")
getwd()
??writecsv
?write.csv
write.csv(Summary, file="C:/Users/damoore/Documents/SummaryCpk.csv")
library(data.table)
library(bit64)
library(ggplot2)
library(stringr)
olddir = getwd()
setwd("C:/Users/damoore/Documents/2014 Projects/Testing/Vregs/EV4B-M/by Jacob")
dt = fread("Vregs - Data combined.csv")
setnames(dt,1,"TestCase")
dt$Step<-NULL
dt$Case<-NULL
dt$Console<-NULL
dt[["Column 11"]]<-NULL
dt[["Column 8"]]<-NULL
setnames(dt,"Console ID","ConsoleID")
dt$RAIL = str_match(dt$TestCase,"(V_[^ ]*)")[,1]
dt$RAIL = gsub("/","-",dt$RAIL)
dt_specs=fread("specs.csv")
dt_specs$Notes<-NULL
dt_specs$RAIL = gsub("^5P0Dual","V_5P0DUAL",dt_specs$RAIL)
dt_specs$RAIL = gsub("^GFXCORE","V_GFXCORE",dt_specs$RAIL)
dt_specs$RAIL = gsub("^MEMCORE","V_MEMCORE",dt_specs$RAIL)
dt_specs$RAIL = gsub("/","-",dt_specs$RAIL)
#dt_specs[Units=="mV",`:=`(Min=Min/1000,Typ=Typ/1000,Max=Max/1000)]
dt$Measurement = gsub("\\*","",dt$Measurement)
dt_specs$Measurement = gsub("\\*","",dt_specs$Measurement)
setkey(dt,RAIL,Measurement)
setkey(dt_specs,RAIL,Measurement)
dt <- dt_specs[dt]
source('~/R/Cpk-summary.R')
Summary = DoCpk(dt)
write.csv(Summary, file="C:/Users/damoore/Documents/SummaryCpk.csv")
install.packages(c("Rcpp", "yaml"))
setwd(olddir)
getwd()
con = url("http://www.jhsph.edu","r")
x = readLines(con)
head(x)
con = url("http://www.danielfmoore.com","r")
x = readLines(con)
head(x)
lapply
help(r)
version()
help()
library("swirl", lib.loc="C:/Users/damoore/Documents/R/win-library/3.1")
library("boot", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("class", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("cluster", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("codetools", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("foreign", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("KernSmooth", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("lattice", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("mgcv", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("nnet", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("Matrix", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("MASS", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("rpart", lib.loc="C:/Program Files/R/R-3.1.0/library")
library("survival", lib.loc="C:/Program Files/R/R-3.1.0/library")
y<-c(1.7, "a")
y
x
getwd()
acs <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
getwd()
acs <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", "acs.csv")
acs<-read.csv("acs.csv")
library(sqldf)
install.packages("sqldf")
library(sqldf)
a<-sqldf("select pwgtp1 from acs where AGEP <50")
View(acs)
View(a)
unique(acs$AGEP)
sqldf("select distinct AGEP from acs")
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
?nchar
htmlCode[1]
htmlCode[2]
htmlCode[3]
nchar(htmlCode[c(10, 20, 30, 100)])
?for
install.packages("foreign")
library(foreign)
?foreign
??foreign
?read.for
?read.fwf
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 5, header=TRUE, skip=3)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 5, header=TRUE, skip=4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 10, sep="     ", header=TRUE, skip=3)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 10, sep="     ", header=TRUE, skip=4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 15, header=TRUE, skip=4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 15, header=TRUE, skip=3)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 10, sep=".....", header=TRUE, skip=4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 10, sep=" ", header=TRUE, skip=4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", sep=" ", header=TRUE, skip=4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 15, sep=" ", header=TRUE, skip=4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", 15, header=TRUE, skip=4)
con = url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
fwffile<-read.fwf(url, 15, header=TRUE, skip=4)
close(con)
widths = c(15,4,4,9,4,9,4,9,4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, skip=4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, skip=3)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, sep="\s")
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, sep="/s")
?sep
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, sep=" ")
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, sep=" ", skip=3)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, sep=" ", skip=2)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, sep=" ", skip=4)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, sep=" ", skip=5)
fwffile<-read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths, header=TRUE, sep=" ", skip=6
)
obj$fork
install.packages("jsonlite")
library("jsonlite", lib.loc="C:/Users/damoore/Documents/R/win-library/3.1")
obj<-fromJSON("https://api.github.com/users/dfmooreqqq/repos")
obj$name
obj$html_url
obj$description
obj$fork
csvlocation = "C:/Users/damoore/Desktop/AppActivityTerminatevSuspend.ss.csv"
ActivityTypeTest <- read.csv(csvlocation, header=TRUE, nrows=1000)
ActivityTypeclasses = sapply(ActivityTypeTest, class)
ActivityType <- read.csv(csvlocation, header = TRUE, colClasses = ActivityTypeclasses)
ActivityType <- read.csv(csvlocation, header = TRUE)
ActivityType$AppActionId2 = as.character(ActivityType$AppActionId)
summarytable = table(ActivityType$AppActionId2, ActivityType$AppType)
rownames(summarytable) = c("launch","terminate","resume","suspend","vis. change","lic. change")
colnames(summarytable) = c("ERA","SRA")
summarytable.transpose = t(summarytable)
plot(summarytable)
x<-list(a=1:5, b=rnorm(10))
x
lapply(x, mean)
lapply(x, min)
x<-1:4
lapply(x, runif)
?apply
library(datasets)
head(airquality)
s<-split(airquality, airquality$Month)
lapply(s, function (x) colMEans(x[, c("Ozone", "Solar.R", "Wind")]))
lapply(s, function (x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
sapply(s, function (x) colMEans(x[, c("Ozone", "Solar.R", "Wind")]))
sapply(s, function (x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
sapply(s, function (x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]), na.rm=TRUE)
sapply(s, function (x) colMeans(x[, c("Ozone", "Solar.R", "Wind")], na.rm=TRUE))
noise<-function(n, mean, sd) { rnorm(n, mean, sd) }
mapply(noise, 1:5, 1:5, 2)
mapply(noise, 1:5, 1:5, 2)
library(datasets)
data(iris)
?iris
iris
mean(iris$Sepal.Length[iris.Species=="virginica"])
mean(iris$Sepal.Length[iris$Species=="virginica"])
apply(iris[, 1:4], 2, mean)
data(mtcars)
mtcars
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(split(mtcars$hp, mtcars$cyl), mean)
a<-sapply(split(mtcars$hp, mtcars$cyl), mean)
a[1] - a[2]
a[1] - a[3]
mean(iris$Sepal.Length[iris$Species=="virginica"])
with(mtcars, tapply(mpg, cyl, mean))
clear()
cls()
?clear
getwd()
source('~/GitHub/ProgrammingAssignment2/test_samplecachemean.R')
makeVector(5)
cachemean(5)
cachemean([1 2])
cachemean(c(1,2))
a<-1:5
cachemean(a)
makeVector(a)
a$getmean()
a$makeVector()
makeVector
makeVector(a)
makeVector(a)$set
makeVector(a)$set(a)
makeVector()$set(a)
b<-makeVector$set(a)
b<-makeVector()$set(a)
b<-makeVector()$set(1:30)
b<-makeVector(1:30)$set(1:30)
makeVector(a)$set(1:30)
b<-makeVector(a)$set(1:30)
makeVector(c)$set(1:30)
cachemean(c)
b$get()
source('~/GitHub/ProgrammingAssignment2/test_samplecachemean.R')
y<-[1:5]
y<-1:5
makeVector(5)$set(1:4)
g<-makeVector(5)$set(1:4)
source('~/GitHub/ProgrammingAssignment2/test_samplecachemean.R')
ross<-open.account(100)
robert<-open.account(200)
daniel<-makeVector(7)
testset<-daniel$set(5)
testget<-daniel$get(5)
testget<-daniel$get()
testmean<-daniel$setmean()
testmean<-daniel$setmean(25)
testgetmean<-daniel$getmean()
cachemean(daniel)
?matrix
testmatrix<-as.matrix(1:10)
View(testmatrix)
testmatrix<-as.matrix(1:25, 5,5)
View(testmatrix)
testmatrix<-matrix(1:25, 5,5)
View(testmatrix)
?inverse
inv<-solve(testmatrix)
testmatrix<-matrix(rnorm(25), 5,5)
inv<-solve(testmatrix)
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
dfm<-makeCacheMatrix(testmatrix)
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
dfm<-makeCacheMatrix(testmatrix)
dfm$doinverse()
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
dfm<-makeCacheMatrix(testmatrix)
dfm$doinverse()
dfm$getinverse()
dfm
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
dfm2<-makeCacheMatrix(testmatrix)
dfm2$getinverse
dfm2$getinverse()
?exists
exists(dfm2$getinverse())
exists(a<0dfm2$getinverse())
exists(a<-dfm2$getinverse())
?is.null
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
cacheSolve(testmatrix)
cacheSolve(dfm)
testcs<-cacheSolve(dfm)
dfm
dfm$getinverse()
is.null(dfm$getinverse())
is.null(dfm2$getinverse())
dfm2$doinverse()
is.null(dfm2$getinverse())
cacheSolve(dfm2)
b<-cacheSolve(dfm2)
b
b()inv
b(dfm2)
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
b<-cacheSolve(dfm2)
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
b<-cacheSolve(dfm2)
dfm
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
b<-cacheSolve(dfm2)
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
b<-cacheSolve(dfm2)
c<-cacheSolve(dfm2)
c==b
c%==%b
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
solve(1:5)
dim(1:5)
dim(testmatrix)
dim(testmatrix)[1]
ncols(testmatrix)
ncol(testmatrix)
nrow(testmatrix)
nrow(testmatrix)==nrow(testmatrix)
nrow(1:5)==nrow(1:5)
nrow(y)==ncol(y)
notsquare=matrix(rnorm(20), 4, 5)
nrow(notsquare)==ncol(notsquare)
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
dfm<-makeCacheMatrix(testmatrix)
dfm
dfm$doinverse()
dfm$issquare()
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
dfm<-makeCacheMatrix(testmatrix)
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
dfm<-makeCacheMatrix(testmatrix)
dfm$doinverse()
invtest<-dfm$getinverse()
dfm2<-makeCacheMatrix(notsquare)
invtest<-dfm2$getinverse()
invtest<-dfm2$doinverse()
dfm2$doinverse()
invtest<-dfm2$getinverse()
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
b<-cacheSolve(dfm2)
source('~/GitHub/ProgrammingAssignment2/cachematrix.R')
str(dfm)
class(dfm)
str(testmatrix)
is.matrix(testmatrix)
str(cacheSolve)
str(plyr)
library("plyr", lib.loc="~/R/win-library/3.1")
str(plyr)
library(datasets)
str(airquality)
str(split(airquality, airquality$month))
str(split(airquality, airquality$months))
str(split(airquality, airquality$Month))
system.time(x<-mean(5))
x<-hilbert(1000)
system.time(readLines("http://www.danielfmoore.com/"))
x<-readLines("http://www.danielfmoore.com/")
show(x)
5+7
getwd()
setwd("C:\\Users\\damoore\\Documents\\GitHub\\GandCD_CourseProject\\UCI HAR Dataset")
#load in needed libraries
library(reshape2)
#Read in files
labels<-read.table("activity_labels.txt")
features<-read.table("features.txt")
train_x<-read.table("train/X_train.txt")
train_y<-read.table("train/y_train.txt")
train_subject<-read.table("train/subject_train.txt")
test_x<-read.table("test/X_test.txt")
test_y<-read.table("test/y_test.txt")
test_subject<-read.table("test/subject_test.txt")
#Label the various columns - this is for step 3
#Here, I'm using the make.names() formula to create good (without special characters) unique names for the data
#Most of the names don't change significantly, however there is some coding to deal with names that otherwise wouldn't be
#unique. These are addressed in the code book
goodnames<-make.names(features$V2, unique=TRUE)
nameconversionlookup <-cbind(as.character(features$V2), goodnames)
names(test_x)<-goodnames
names(train_x)<-goodnames
names(labels)<-c("ActivityNum", "ActivityLabel")
names(test_y)<-"ActivityNum"
names(train_y)<-"ActivityNum"
names(test_subject)<-"Subject"
names(train_subject)<-"Subject"
##bind the test and training data sets into each data sets
testdataset <- cbind(test_x, test_y, test_subject)
traindataset <- cbind(train_x, train_y, train_subject)
testdataset$DataSet <- "Test"
traindataset$DataSet <- "Train"
#now put the full datasets together
fulldataset<-rbind(testdataset, traindataset)
summary(fulldataset)
#define columns to keep in step 2 where we extract only the measurements on mean and std
greplstring = "std|mean|ActivityNum|Subject|DataSet"
meanstddataset<-fulldataset[,which(grepl(greplstring,names(fulldataset)))]
#Merges the Activity labels onto the dataset
meanstddatasetw_labels<-merge(meanstddataset, labels)
#Use Melting and dcasting from the reshape2 library to get the mean for each numeric column by ActivityLabel and Subject
numericcol<-names(meanstddatasetw_labels[,sapply(meanstddatasetw_labels, is.numeric)])[-1][-80] #I need the -1 so that ActivityNum isn't included
tablemelt<-melt(meanstddatasetw_labels, id=c("ActivityNum", "ActivityLabel", "Subject"), measure.vars=numericcol)
avgtable <- dcast(tablemelt, ActivityLabel+Subject~variable, mean)
#clean up some variables that I'm done with
suppressWarnings(rm("features","goodnames", "test_subject", "test_x", "test_y", "testdataset", "train_subject", "train_x", "train_y", "traindataset", "greplstring", "labels", "meanstddataset", "tablemelt"))
summary(avgtable)
a<-summary(avgtable)
a<-data.frame(a)
